---
title: "SME Loan Documentation Phase2"
author: "Anurag Swain"
date: "7 August 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Project Stages 



### Phase 2
<br />1.Dataset used
<br />1.1.Using Dataset which has companies with all the important core attributes present
<br />2.Data Wrangling
<br />2.1.Wrangling the dataset to obtain 
<br />3.Creating a Dataset where default companies to non-default are propotionate
<br />4.Data Cleaning and imputation
<br />5.Outlier treatment and Capping
<br />6.Data Normalisation
<br />7.Data modelling using Machine Learning






## Introduction 

Here we will be using the ScoringDataset which contains companies which have all the important attributes present.
The list of companies was obtained from Phase1.The ScoringDataset again contains data which has attributes recurring, with the year appended along with the column name.So the data need to be reformatted again just like in phase1 


##1.Dataset used

The data is read from the ScoringDataset.csv into dataframe ScoringDataset
The attributes are recurring with the year appended 

```{r }

colnames(ScoringDataset[,1:40])


```

##2.Data Wrangling

The data from ScoringDataset is then extracted into seperate datasets where the year of the finacial data is dispalyed in a column and stored in a list (MajorAttri,CostofGoodsSoldlist,interestexp_otherattri,salesnattri,Ratingsofcompany - all these list have data from 2009-2018 stored in the list with index1-2009 and index10-2018).

</br>1.Firmographics - Details about the firm
</br>2.MajorAttri_listmerged - Has Balance sheet data (2009-2018):Total liabilities,Total capital...
</br>3.salesnattri_listmerged -Has Sales data (2009-2018)
</br>4.interestexp_otherattri_listmeged - Has Expenses data (2009-2018)
</br>5.CostofGoodsSoldlist_merged - Has cost of goods sold data (2009-2018)
</br>6.Ratingsofcompany_listmerged - Has Ratings of the company (2009-2018)
```{r }

colnames(Firmographics)
colnames(MajorAttri_listmerged)
summary(CostofGoodsSoldlist[[1]])
summary(CostofGoodsSoldlist[[2]])
colnames(CostofGoodsSoldlist_merged)
colnames(interestexp_otherattri_listmeged)
colnames(salesnattri_listmerged)



```


All these seperate data sets were then merged to create a Merged_Masterdata, which has all the attributes present

```{r }
dim(Merged_Masterdata)
colnames(Merged_Masterdata)

```


##3.Creating a Dataset where default companie to non-default are propotionate

We now have the same company occuring multiple time corresponding to the year of its financial data.So we need to pick a particular year for a particular company.We will use the code from SubsetScoringDataset.R to obtain the Final_dataset(For companies that has defaulted, ie where the default flag is set to 1, we select the financials of the previous year, and for non-default companies the records corresponding to its latest financial year was chosen )


```{r }
dim(Final_dataset)
colnames(Final_dataset)
```


#### Before imputing
Missing values in a lot non-core attributes before imputuing
```{r }
summary(Final_dataset$Total.liabilities)
summary(Final_dataset$Total.expenses)

```


##4.Data Cleaning and imputation

In script Clean_Final_dataset.R , since we already have the daat with core important attributes present we will impute the missing attributes with mean-imputation based on Industry.group(more specific grouping) and then on basis of Entity.type (generalised grouping). 

#### After imputing
```{r }
summary(Final_dataset_meanimpute$Total.liabilities)
summary(Final_dataset_meanimpute$Total.expenses)

```




All the attributes with numerical values were imputed.The imputed dataset (Final_dataset_meanimpute) is then used to create the derived attributes.

#### Derived Attributes added
```{r }
colnames(Final_dataset_meanimpute)

```



##5.Outlier treatment and Capping

In script Outlierdetection.R ,we have capped values below 5 quantile (5%) and above 95 quantile (95%). 

#### Before capping Current Ratio
```{r }
library(ggplot2)
library(scales)

summary(Final_dataset_bkup$CurrentRatio)
ggplot(Final_dataset_bkup,aes(CurrentRatio))+geom_histogram(bins = 30)+scale_x_continuous(limits = c(-5,50))


```


#### After capping Current Ratio
```{r }
library(ggplot2)
library(scales)

summary(Final_dataset_capped_5to95perc$CurrentRatio)
ggplot(Final_dataset_capped_5to95perc,aes(CurrentRatio))+geom_histogram(bins=30)


```

### Before capping Inventory Days
```{r }
library(ggplot2)
library(scales)

summary(Final_dataset_bkup$InventoryDays)
ggplot(Final_dataset_bkup,aes(InventoryDays))+geom_histogram(bins = 30)+scale_x_continuous(limits = c(-10,3000))


```


### After capping Inventory Days
```{r }
library(ggplot2)
library(scales)

summary(Final_dataset_capped_5to95perc$InventoryDays)
ggplot(Final_dataset_capped_5to95perc,aes(InventoryDays))+geom_histogram(bins=30)


```

### Before capping Payable Days
```{r }
library(ggplot2)
library(scales)

summary(Final_dataset_bkup$PayableDays)
ggplot(Final_dataset_bkup,aes(PayableDays))+geom_histogram(bins = 30)+scale_x_continuous(limits = c(-10,3000))



```

### After capping Payable Days
```{r }
library(ggplot2)
library(scales)

summary(Final_dataset_capped_5to95perc$PayableDays)
ggplot(Final_dataset_capped_5to95perc,aes(PayableDays))+geom_histogram(bins = 30)



```

Before and after capping summary for derived attributes Final_dataset_bkup has before capping data and Final_dataset_capped_5to95perc has after capping data
```{r}


summary(Final_dataset_bkup$InventoryDays)
summary(Final_dataset_capped_5to95perc$InventoryDays)

summary(Final_dataset_bkup$ReceivableDays)
summary(Final_dataset_capped_5to95perc$ReceivableDays)

summary(Final_dataset_bkup$PayableDays)
summary(Final_dataset_capped_5to95perc$PayableDays)



```

##6.Data Normalisation
Here we used min-max normalisation to normalise the data to between 0 and 1
Sharing normalisations for a few attributes

#### Before Normalising payable days
```{r }
library(ggplot2)
library(scales)

summary(Final_dataset_capped_5to95perc$PayableDays)
ggplot(Final_dataset_capped_5to95perc,aes(PayableDays))+geom_histogram(bins = 30)



```

#### After Normalising payable days
```{r }
library(ggplot2)
library(scales)

summary(Final_dataset_Norm_5to95$PayableDays)
ggplot(Final_dataset_Norm_5to95,aes(PayableDays))+geom_histogram(bins=30)



```


#### Before Normalising interest-ratio coverage
```{r }
library(ggplot2)
library(scales)

summary(Final_dataset_capped_5to95perc$InterestRatioCoverage)
ggplot(Final_dataset_capped_5to95perc,aes(InterestRatioCoverage))+geom_histogram(bins = 30)



```

#### After Normalising interest-ratio coverage
```{r }
library(ggplot2)
library(scales)

summary(Final_dataset_Norm_5to95$InterestRatioCoverage)
ggplot(Final_dataset_Norm_5to95,aes(InterestRatioCoverage))+geom_histogram(bins=30)



```




##7.Data modelling using Machine Learning

### Using logistic regression

```{r}

Model_logistic<-glm(Default.Flag~CurrentRatio+QuickRatio+InterestRatioCoverage+DebtEquityRatio+DSCR+EBITA+PBT_percentage+InventoryDays+ReceivableDays+PayableDays+ROCE+RONW+FixedAssetsTurnover+AgeofCompany+BSE_Flag+EntityTypePublicFlag+EntityTypePrivateFlag+Ownershipgrp_PrivateForeign+Ownershipgrp_PrivateIndian,family=binomial(link='logit'),data = Final_datasetTrain_Norm_5to95)

summary(Model_logistic)
```

```{r}
PredictedTrain_logistic<-predict(Model_logistic,Final_datasetTrain_Norm_5to95,type = "response")
table(actualvalue=Final_datasetTrain_Norm_5to95$Default.Flag,predictedvalue=PredictedTrain_logistic>0.5)
```
The training set gives accuracy of about 80%

```{r]}
PredictedTest_logistic<-predict(Model_logistic,Final_datasetTest_Norm_5to95,type = "response")
table(actualvalue=Final_datasetTest_Norm_5to95$Default.Flag,predictedvalue=PredictedTest_logistic>0.5)
```
The testing set gives accuracy of 78%


### Using Randomforest
#### For default mtry

```{r}
print(bestmtry)

```

For mtry=4
The Training accuracy was 95%
The testing accuracy was 80%


#### On mtry =2

```{r}
table(actualvalue=Final_datasetTrain_Norm_5to95$Default.Flag,predictedvalue=PredictedTrain_randomforest)
```
Training accuracy :80%

```{r}
table(actualvalue=Final_datasetTest_Norm_5to95$Default.Flag,predictedvalue=PredictedTest_randomforest)
```
Testing accuracy : 79.7%